app端  app登录功能  文章显示功能  热点文章推荐  热搜功能  点赞评论收藏功能  文章推荐功能

自媒体端  自媒体用户创建  文章发布  素材管理

平台管理端  管理员登录  文章发布内容的文章审核  用户列表显示  文章列表显示  文章频道管理  敏感词管理



app端  

1.app端用户登录功能（手动加密：md5+随机字符串

2.app端文章查看（1.文章列表加载（分库分表）   2.文章详情查看（freemarker  minIO)

3.app端文章搜索（1.文章搜索（ES库）   2.搜索记录（MongoDB)(保存搜索记录、加载搜索记录列表、删除搜索记录、关键字联想)

4.热点文章定时计算（xxl-job)

5.热点文章实时计算(kafkaStream)



自媒体端

1.自媒体素材管理（1.素材上传  2.素材列表查询

2.自媒体文章管理（1.查询所有频道  2.查询自媒体文章  3.文章发布





文章发布：

​	延迟任务精准发布文章

​	kafka异步通知文章上下架

​			自媒体用户发布文章  ---  app端用户查看文章  -- 因此 这里的上下架是指app端文章上下架





# DAY01--环境搭建 spring cloud微服务

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240514114055506.png" alt="image-20240514114055506" style="zoom:67%;" />

## 1.登录功能

- 用户点击**开始使用**

  登录后的用户权限较大，可以查看，也可以操作（点赞，关注，评论）

- 用户点击**不登录，先看看**

​       游客只有查看的权限

### 手动加密（md5+随机字符串）

md5是不可逆加密，md5相同的密码每次加密都一样，不太安全。在md5的基础上手动加盐（salt）处理

注册->生成盐

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240514115849857.png" alt="image-20240514115849857" style="zoom:67%;" />

登录->使用盐来配合验证

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240514115939865.png" alt="image-20240514115939865" style="zoom:67%;" />

## 接口工具postman、swagger、knife4j

## 网关

注册中心  配置管理

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240514124706150.png" alt="image-20240514124706150" style="zoom:67%;" />



<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240514124736609.png" alt="image-20240514124736609" style="zoom:67%;" />

我们这个项目中一共涉及到三个网关，我们现在要完成的是第三个

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240514130801447.png" alt="image-20240514130801447" style="zoom:50%;" />

### 全局过滤器实现jwt校验

1.在app-gateway中写全局过滤器（AuthorizeFilter)

​			获取request和response对象

​			通过request判断是否是登录，若是，则直接放行

​																若不是，则从request的header中获取token

​			若token不存在 返回给前端401错误，结束请求

​			若token存在，解析token中的数据，判断token是否过期

​									token过期或者解析失败，返回401

​									都没问题则放行

## 前端集成

### 部署思路

通过nginx来进行配置，功能如下

- 通过nginx的反向代理功能访问后台的网关资源

- 通过nginx的静态服务器功能访问前端静态页面

  <img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240514133329855.png" alt="image-20240514133329855" style="zoom:67%;" />

### 配置nginx

①：解压资料文件夹中的压缩包nginx-1.18.0.zip

②：解压资料文件夹中的前端项目app-web.zip

③：配置nginx.conf文件

在nginx安装的conf目录下新建一个文件夹`leadnews.conf`,在当前文件夹中新建`heima-leadnews-app.conf`文件

nginx.conf   把里面注释的内容和静态资源配置相关删除，引入heima-leadnews-app.conf文件加载

④ ：启动nginx

​    在nginx安装包中使用命令提示符打开，输入命令nginx启动项目

​    可查看进程，检查nginx是否启动

​	重新加载配置文件：`nginx -s reload`

⑤：打开前端项目进行测试  -- >  http://localhost:8801

​     用谷歌浏览器打开，调试移动端模式进行访问

# DAY02--app端文章查看

## 1.文章列表加载

**需求分析**

1,在默认频道展示10条文章信息

2,可以切换频道查看不同种类文章

3,当用户下拉可以加载最新的文章（分页）本页文章列表中发布时间为最大的时间为依据

4,当用户上拉可以加载更多的文章信息（按照发布时间）本页文章列表中发布时间最小的时间为依据

5，如果是当前频道的首页，前端传递默认参数：

- maxBehotTime：0（毫秒）

- minBehotTime：20000000000000（毫秒）--->2063年

### 分库分表（P21

app端文章列表

这里用的是表的拆分  垂直分表

![image-20240430135220779](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240430135220779.png)

![image-20240430135310418](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240430135310418.png)

## 



## freemarker模板引擎

FreeMarker 是一款 模板引擎： 即一种基于模板和要改变的数据， 并用来生成输出文本(HTML网页，电子邮件，配置文件，源代码等)的通用工具。 它不是面向最终用户的，而是一个Java类库，是一款程序员可以嵌入他们所开发产品的组件。

​	模板编写为FreeMarker Template Language (FTL)。它是简单的，专用的语言， *不是* 像PHP那样成熟的编程语言。 那就意味着要准备数据在真实编程语言中来显示，比如数据库查询和业务运算， 之后模板显示已经准备好的数据。在模板中，你可以专注于如何展现数据， 而在模板之外可以专注于要展示什么数据。 

## minIO--分布式文件系统

MinIO基于Apache License v2.0开源协议的对象存储服务，可以做为云存储的解决方案用来保存海量的图片，视频，文档。由于采用Golang实现，服务端可以工作在Windows,Linux, OS X和FreeBSD上。配置简单，基本是复制可执行程序，单行命令可以运行起来。

MinIO兼容亚马逊S3云存储服务接口，非常适合于存储大容量非结构化的数据，例如图片、视频、日志文件、备份数据和容器/虚拟机镜像等，而一个对象文件可以是任意大小，从几kb到最大5T不等。

### 对象存储方式对比

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240513103137205.png" alt="image-20240513103137205" style="zoom:50%;" />

**分布式文章存储系统**

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240513103331127.png" alt="image-20240513103331127" style="zoom:50%;" />

### 封装MinIO为starter

由于每个微服务可能都有上传文件的需求，因此将其集成为一个starter，里面封装minIO

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240513105051223.png" alt="image-20240513105051223" style="zoom:67%;" />



## 2.文章详情

像一些大文本的内容，一般不会直接去查询数据库，通常做成静态模板进行展示

原始：根据文章ID到数据库中查询文章内容，然后把内容返给页面

现在：根据文章表中的html的url到minIO中去访问当前的静态页面

![image-20240520131430121](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240520131430121.png)

**实现步骤**

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240513111723538.png" alt="image-20240513111723538" style="zoom:67%;" />



<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240513111649859.png" alt="image-20240513111649859" style="zoom:50%;" />

## 静态模板展示（freemaeker  minIO

大文本内容一般不会直接去查询数据库，通常用静态模板展示

![image-20240501094636928](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240501094636928.png)

# DAY03 

## 网关过滤器 拦截器（P45

![image-20240503111502036](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240503111502036.png)

网关解析token并放入header

拦截器的定义与配置

## 1.自媒体素材管理

### 1.1素材上传

①：前端发送上传图片请求，类型为MultipartFile

②：网关进行token解析后，把解析后的用户信息存储到header中

③：自媒体微服务使用拦截器获取到header中的的用户信息，并放入到threadlocal中

④：先把图片上传到minIO中，获取到图片请求的路径——（2.2.5查看具体功能实现）

⑤：把用户id和图片上的路径保存到素材表中——（2.2.5查看具体功能实现）

### 1.2素材列表查询

## 2.自媒体文章管理

### 2.1查询所有频道



### 2.2查询自媒体文章



### 2.3文章发布

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240521115438479.png" alt="image-20240521115438479" style="zoom:67%;" />

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240521122310805.png" alt="image-20240521122310805" style="zoom:67%;" />

涉及到的表：wm_news 自媒体文章表、wm_material 素材表、wm_news_material 文章素材关系表

**实现思路**

1.前端提交发布或保存为草稿

2.后台判断请求中是否包含了文章id

3.如果不包含id,则为新增

​	3.1 执行新增文章的操作

​	3.2 关联文章内容图片与素材的关系

​	3.3 关联文章封面图片与素材的关系

4.如果包含了id，则为修改请求

​	4.1 删除该文章与素材的所有关系

​	4.2 执行修改操作

​	4.3 关联文章内容图片与素材的关系

​	4.4 关联文章封面图片与素材的关系

**实现步骤**

1.保存或修改文章

2.判断是否为草稿  若为草稿 结束当前方法

3.不是草稿 保存文章内容与图片的关系

4.不是草稿 保存文章封面与图片的关系

# DAY05--延迟任务精准发布文章

## 延迟任务

### 消息队列实现延迟任务

- TTL：Time To Live (消息存活时间)

- 死信队列：Dead Letter Exchange(死信交换机)，当消息成为Dead message后，可以重新发送另一个交换机（死信交换机）

![image-20210513150319742](D:\黑马黑马头条java\day05-延迟队列精确发布文章\讲义\延迟任务精准发布文章.assets\image-20210513150319742.png)

### redis实现延迟任务（看javaguide

#### Redis 过期事件监听实现



#### Redisson 内置的延时队列(项目中采用？)

zset数据类型的去重有序（分数排序）特点进行延迟。例如：时间戳作为score进行排序

![image-20210513150352211](D:\黑马黑马头条java\day05-延迟队列精确发布文章\讲义\延迟任务精准发布文章.assets\image-20210513150352211.png)

## 本项目利用redis实现延迟任务

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240518122415924.png" alt="image-20240518122415924" style="zoom:50%;" />





实现思路

![image-20210513150440342](D:\黑马黑马头条java\day05-延迟队列精确发布文章\讲义\延迟任务精准发布文章.assets\image-20210513150440342.png)

## redis中的数据类型



## 1.1添加任务

先将任务添加到数据库，再根据执行时间选择部分数据加入到redis的list或zset中

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240518123436482.png" alt="image-20240518123436482" style="zoom:67%;" />





## 1.2删除任务

先将任务从数据库中删除，再根据执行时间判断数据是否还存在于redis的list或zset中，若存在，则进一步删除

## 1.3消费任务

按照类型和优先级从redis的list中拉取任务；

更新数据库

## 1.4未来数据定时刷新

### redis管道技术

redis 是 C/S 模式，即客户端 + 服务端。当两端想要通信时，需要先建立特定的 TCP 握手连接，在进行通信时，采用 发送请求 -> 等待响应 这种`一问一答`模式。

这是最经典的一种模式，应用非常广泛。如果你没有批量处理需求，这种模式应该是最合适的。

但如果你遇到一些特殊的场景，比如一次性要查询 100、1000 次 redis，这样的 1000 次的请求 + 应答，主要的消耗都浪费在网络通信中，非常不划算。

那能不能做到一次性批量请求和批量回复？

其实，这种场景不仅是请求 redis，还有很多类似于这种多次请求的诉求，比如 mysql、http 等都会遇到，解决思路就是 批量操作，以减少网络损耗。

### 具体实现

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240518130019789.png" alt="image-20240518130019789" style="zoom:80%;" />

![image-20240518130659669](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240518130659669.png)

### 定时任务

@Scheduled(cron = "0 */1 * * * ?")

每分钟执行一次

### redis管道

Redis 客户端与 Redis 服务器之间使用 TCP 协议进行连接，一个客户端可以通过一个 socket 连接发起多个请求命令。每个请求命令发出后 client 通常会阻塞并等待 redis 服务器处理，redis 处理完请求命令后会将结果通过响应报文返回给 client，因此当执行多条命令的时候都需要等待上一条命令执行完毕才能执行。
而管道（pipeline）可以一次性发送多条命令并在执行完后一次性将结果返回，pipeline 通过减少客户端与 redis 的通信次数来实现降低往返延时时间，而且 Pipeline 实现的原理是队列，而队列的原理是时先进先出，这样就保证数据的顺序性。 Pipeline 的默认的同步的个数为53个，也就是说 arges 中累加到53条数据时会把数据提交。其过程如下图所示：client 可以将三个命令放到一个 tcp 报文一起发送，server 则可以将三条命令的处理结果放到一个 tcp 报文返回。

### 实现思路

获取所有未来数据集合zset的key值

根据执行时间 获取该组key下当前需要消费的任务数据

将这些任务数据添加到消费者队列list中



## 1.5分布式锁解决集群下的方法抢占执行

#### 问题描述

启动两台heima-leadnews-schedule服务，每台服务都会去执行refresh定时任务方法

#### 解决方案（后期可以优化为redisson实现

分布式锁：zookeeper实现；redis实现

我们项目中采用的是redis实现的分布式锁 

sexnx （SET if Not eXists） 命令在指定的 key 不存在时，为 key 设置指定的值。

这种加锁的思路是，如果 key 不存在则为 key 设置 value，如果 key 已存在则 SETNX 命令不做任何操作

#### 实现

在工具类CacheService中添加加锁方法tryLock()

### 1.6数据库任务定时同步到redis

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240518133320370.png" alt="image-20240518133320370" style="zoom:80%;" />



## 延迟队列解决精准时间发布文章

![image-20240510140930009](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240510140930009.png)

### 延迟队列提供对外接口（看讲义

### 发布文章集成添加延迟队列接口

### 消费任务进行审核文章





# DAY06 Kafka--及异步通知文章上下架

## 同步通讯和异步通讯

Feign调用就属于同步方式

同步调用的优点：

- 时效性较强，可以立即得到结果

同步调用的问题：

- 耦合度高
- 性能和吞吐能力下降
- 有额外的资源消耗
- 有级联失败问题

为了解除事件发布者与订阅者之间的耦合，两者并不是直接通信，而是有一个中间人（Broker）。发布者发布事件到Broker，不关心谁来订阅事件。订阅者从Broker订阅事件，不关心谁发来的消息。Broker 是一个像数据总线一样的东西，所有的服务要接收数据和发送数据都发到这个总线上，这个总线就像协议一样，让服务间的通讯变得标准和可控。MQ，中文是消息队列（MessageQueue），字面来看就是存放消息的队列。也就是事件驱动架构中的Broker。

好处：

- 吞吐量提升：无需等待订阅者处理完成，响应更快速

- 故障隔离：服务没有直接调用，不存在级联失败问题
- 调用间没有阻塞，不会造成无效的资源占用
- 耦合度极低，每个服务都可以灵活插拔，可替换
- 流量削峰：不管发布事件的流量波动多大，都由Broker接收，订阅者可以按照自己的速度去处理事件

缺点：

- 架构复杂了，业务没有明显的流程线，不好管理
- 需要依赖于Broker的可靠、安全、性能

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240516100217196.png" alt="image-20240516100217196" style="zoom:67%;" />

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240516100449066.png" alt="image-20240516100449066" style="zoom:67%;" />

## kafka相关知识

### kafka高可用设计

**集群方案**

- Kafka 的服务器端由被称为 Broker 的服务进程构成，即一个 Kafka 集群由多个 Broker 组成

- 这样如果集群中某一台机器宕机，其他机器上的 Broker 也依然能够对外提供服务。这其实就是 Kafka 提供高可用的手段之一

**备份机制**

如果leader失效后，需要选出新的leader，选举的原则如下：

第一：选举时优先从ISR中选定，因为这个列表中follower的数据是与leader同步的

第二：如果ISR列表中的follower都不行了，就只能从其他follower中选取





## 自媒体文章上下架

自媒体用户发布文章  ---  app端用户查看文章  -- 因此 这里的上下架是指app端文章上下架

自媒体端微服务操作上下架 -- 通知  文章微服务上下架文章

首先我们想到的时用feign远程调用的方式，但是这种方式会产生系统的耦合，因此这里我们采用MQ的方式。

![image-20240509112019127](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240509112019127.png)





# DAY07--app端文章搜索

## 1.文章搜索

- ElasticSearch环境搭建

- 索引库创建  查询所有的文章信息，批量导入到es索引库中

- 文章搜索多条件复合查询

- 索引数据同步

  

### ES库

为了加快检索的效率，在查询的时候不会直接从数据库中查询文章，需要在elasticsearch中进行高速检索。

![image-20240509093811577](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240509093811577.png)

启动项目进行测试，至少要启动文章微服务，用户微服务，搜索微服务，app网关微服务，app前端工程

#### mysql和es的比较

![image-20240516135749129](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240516135749129.png)

因此在企业中，往往是两者结合使用：

- 对安全性要求较高的写操作，使用mysql实现
- 对查询性能要求较高的搜索需求，使用elasticsearch实现
- 两者再基于某种方式，实现数据的同步，保证一致性

分词器的作用是什么？

- 创建倒排索引时对文档分词
- 用户搜索时，对输入的内容分词

#### 索引库操作

索引库操作有哪些？

- 创建索引库：PUT /索引库名
- 查询索引库：GET /索引库名
- 删除索引库：DELETE /索引库名
- 添加字段：PUT /索引库名/_mapping

倒排索引结构虽然不复杂，但是一旦数据结构改变（比如改变了分词器），就需要重新创建倒排索引，这简直是灾难。因此索引库**一旦创建，无法修改mapping**。

#### 文档操作

文档操作有哪些？

- 创建文档：POST /{索引库名}/_doc/文档id   { json文档 }
- 查询文档：GET /{索引库名}/_doc/文档id
- 删除文档：DELETE /{索引库名}/_doc/文档id
- 修改文档：
  - 全量修改：PUT /{索引库名}/_doc/文档id { json文档 }
  - 增量修改：POST /{索引库名}/_update/文档id { "doc": {字段}}

### 添加文章时在ES中添加数据（kafka)

![image-20240509100022012](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240509100022012.png)

发送消息的逻辑写在ArticleFreemarkServiceImpl中将文章上传到minIO之后

#### ES为什么查询效率高呢？

## 2.搜索记录

### mongodb

#### mongodb有什么特点？

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240518105726180.png" alt="image-20240518105726180" style="zoom:80%;" />

#### mongodb适合什么应用场景？

![image-20240518110036366](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240518110036366.png)



### 保存搜索记录

用户的搜索记录，需要给每一个用户都保存一份，数据量较大，要求加载速度快，通常这样的数据存储到mongodb更合适，不建议直接存储到关系型数据库中

![image-20240509101609770](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240509101609770.png)

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240509103108505.png" alt="image-20240509103108505" style="zoom:50%;" />



<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240509103136046.png" alt="image-20240509103136046" style="zoom:50%;" />

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240509103207051.png" alt="image-20240509103207051" style="zoom:50%;" />



这个功能是在文章搜索功能的实现类中，在第一步检查参数结束之后，异步调用 保存搜索记录（**p14（这里涉及到网关中过滤器获取用户信息并存入header中  和拦截器中解析header将apUser.userId放入ThreadLocal中**

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240509102933491.png" alt="image-20240509102933491" style="zoom:50%;" />

### 加载搜索记录列表

### 删除搜索记录

### 关键字联想词

根据用户输入的关键字展示联想词

用mongdb实现  在查询前已经将联想词表ap_associate_words.js导入到mongo中

# DAY10--热点文章定时计算

## xxl-job分布式任务调度框架

spring传统的定时任务@Scheduled，但是这样存在这一些问题 ：

- 做集群任务的重复执行问题（分布式锁解决

- cron表达式定义在代码之中，修改不方便

- 定时任务失败了，无法重试也没有统计

- 如果任务量过大，不能有效的分片执行

解决这些问题的方案为：

xxl-job 分布式任务调度框架

![image-20240509115901618](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240509115901618.png)

## 热点文章定时计算

![image-20240510203324511](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240510203324511.png)

1.在article微服务下的HotarticleImpl下，先检索出前五天所有的文章数据，并计算出其分值

2.feign远程调用wemedia微服务检索出有几个频道

3.按频道检索出每个频道的文章

4.给文章进行排序，取30条分值较高的文章存入redis （ key：频道id   value：30条分值较高的文章）

即cacheService.set(key, JSON.toJSONString(hotArticleVos));

5.测试前要启动wemedia , schedule微服务

### feign远程调用

在计算出文章分值后，要查询每个频道，这时需要feign远程接口调用wemedia微服务中的wmChannelService来进行查询



## 定时任务

1.在xxl-job-admin中新建执行器和任务

新建执行器：leadnews-hot-article-executor

新建任务：路由策略为轮询，Cron表达式：0 0 2 * * ? （每天凌晨2点执行一次）



2.leadnews-article中集成xxl-job（参考xxljob-demo项目

即article微服务下的config创建XxlJobConfig类添加相关配置（参考xxljob-demo项目），其中一些属性的赋值放到nacos中

3.leadnews-article微服务下的job目录下创建具体任务ComputeHotArticleJob

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240510210142496.png" alt="image-20240510210142496" style="zoom:67%;" />





# DAY11--热点文章实时计算

![image-20240513112949346](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240513112949346.png)

## 1.kafkastream

### 应用场景

- 日志分析

  网站的用户访问日志进行实时的分析，计算访问量，用户画像，留存率等等，实时的进行数据分析，帮助企业进行决策

- 大屏看板统计

  可以实时的查看网站注册数量，订单数量，购买数量，金额等。

- 公交实时数据

  可以随时更新公交车方位，计算多久到达站牌等

- 实时文章分值计算

  头条类文章的分值计算，通过用户的行为实时文章的分值，分值越高就越被推荐。

### 入门案例

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240513122428271.png" alt="image-20240513122428271" style="zoom:67%;" />

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240513122705439.png" alt="image-20240513122705439" style="zoom:80%;" />

## 2.实时计算

1.用户行为微服务发送消息给kafka

2.文章微服务中进行stream聚合处理（HotArticleStreamHandler.java

​			kafkastream集成到文章微服务

​			接收消息

​			流式处理

​			发送消息

3.创建监听接收聚合之后的数据（article微服务下的listener中ArticleIncrHandlerListener.java

4.更新数据库数量（更新文章的阅读、点赞、收藏、评论的数量）(ApArticleServiceImpl.java

5.重新计算文章的分值(ApArticleServiceImpl.java)

6.更新缓存中的数据  当前文章对应频道的热点数据  推荐对应的热点数据（ApArticleServiceImpl.java

​			如果缓存中存在该文章，只更新其分值即可

​			如果缓存中不存在该文章，查询缓存中分值最小的一条数据，进行分值比较，如果当前文章的分值大于缓存中的数据，就进行替换





<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240513130054104.png" alt="image-20240513130054104" style="zoom:80%;" />

# DAY12

## jenkins持续集成工具

Jenkins的特征：

- 开源的 Java语言开发持续集成工具，支持持续集成，持续部署。
- 易于安装部署配置：可通过 yum安装,或下载war包以及通过docker容器等快速实现安装部署，可方便web界面配置管理。
- 消息通知及测试报告：集成 RSS/E-mail通过RSS发布构建结果或当构建完成时通过e-mail通知，生成JUnit/TestNG测试报告。
- 分布式构建：支持 Jenkins能够让多台计算机一起构建/测试。
- 文件识别： Jenkins能够跟踪哪次构建生成哪些jar，哪次构建使用哪个版本的jar等。
- 丰富的插件支持：支持扩展插件，你可以开发适合自己团队使用的工具，如 git，svn，maven，docker等。

## 1.后端项目部署

![image-20240515095835690](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240515095835690.png)



项目上传到gitee

1.jenkins安装配置

​		插件安装

​				Maven Integration plugin： Maven 集成管理插件。

​				Docker plugin： Docker集成插件。

​				GitLab Plugin： GitLab集成插件。

​				Publish Over SSH：远程文件发布插件。SSH: 远程脚本执行插件。

​		100服务器中 环境准备：安装docker, jdk, git, maven

2.jenkins工具配置

​			在jenkins管理页面中集成环境， Manage Jenkins-->Tool Configuration ，需要指定环境的目录

3.后端项目部署

​			多环境切换

​			1.代码上传到gitee

​			2.微服务集成docker配置

​				部署的每一个微服务都是先创建docker镜像后创建对应容器启动（使用dockerfile-maven-plugin插件，可以直接把微服务创建为镜像使用（更省事））；配置pom文件和dockerfile文件

​			3.基础依赖打包配置

​				在微服务运行之前需要在本地仓库中先去install所依赖的jar包，所以第一步应该是从git中拉取代码，并且把基础的依赖部分安装到仓库中

​				1.新建任务：heima-leadnews

​				2.找到自己指定的git仓库，设置用户名和密码

​				3.把基础依赖信息安装到服务器上的本地仓库

​				4.执行（从git中拉取代码 编译打包

​			4.微服务打包配置（所有微服务打包的方式类似，以heima-leadnews-user微服务为例

​				1.新建任务

​				2.找到自己指定的git仓库，设置用户名和密码

​				3.执行maven命令  执行shell脚本

​				4.执行日志（拉取代码，编译打包，构建镜像，清理容器，创建新容器

​			5.部署服务到远程服务器上（具体步骤见讲义

​				使用jenkins（192.168.200.100）把微服务打包部署到192.168.200.130服务器上

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240515123516146.png" alt="image-20240515123516146" style="zoom:67%;" />

100服务器 使用dockerfile创建容器

# 总的知识点汇总

## MQ相关

微服务间基于Feign的调用就属于同步方式，存在一些问题。

同步调用的优点：时效性较强，可以立即得到结果

同步调用的问题：耦合度高   性能和吞吐能力下降    有额外的资源消耗    有级联失败问题



异步调用常见实现就是事件驱动模式

异步通信的优点：耦合度低    吞吐量提升    故障隔离    流量削峰

异步通信的缺点：依赖于Broker的可靠性、安全性、吞吐能力     架构复杂了，业务没有明显的流程线，不好追踪管理

![image-20240514142540619](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240514142540619.png)

## 接口工具postman、swagger、knife4j





## kafka异步通信怎么实现的

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240612131418942.png" alt="image-20240612131418942" style="zoom:67%;" />

## 定时计算是什么？详细说说

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240612131339065.png" alt="image-20240612131339065" style="zoom:67%;" />

## 为什么用list数据结构 list有序和kafka怎么保证有序  分布式运行怎么有序 为什么用list

## 锁加在哪？粗粒度如何？

## ES建立索引 ES面对大的热数据怎么办

## 缓存穿透与缓存击穿

## 扩展场景题  大部分与分布式、高并发、大数据量有关

