简历重点记忆

# 黑马头条

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240612162108387.png" alt="image-20240612162108387" style="zoom:50%;" />

## 使用freemarker和minIO完成文章详情展示功能，缓解了访问数据库的压力。

像blob和text这样的字段，名义上是为存储很大的数据而设计的类型。但这正因为如此，这跟关系数据库使用table的设计理念是冲突的。table中的每一列数据都是定长的，比如varchar(32)。但blob和text的上限太长了，MySQL不可能将它们存储在table中，因而会使用专门的外部存储区域进行存储，数据行内存储指针。这样做的其中一个结果是会导致多一次磁盘IO，性能开销比较严重。

为了有效存储列类型为BLOB或TEXT的大数据类型，一般将列的值存放在行溢出页，而数据页存储的行数据只包含BLOB或TEXT类型数据列前一部分数据。

数据页由许多的行数据组成，每行数据由列组成， 对于列类型为BLOB的数据，InnoDB存储引擎只存储前20字节，而该列的完整数据则存放在BLOB的行溢出页中。在这种方式下，数据页中能存放大量的行数据，从而 提高了数据的查询效率。

mysql的io以page为单位  page大小为16KB，而BLOB和TEXT最大为65536字节，因此不可能存储的下

频繁读不频繁写的新闻资讯类文本，在保存的时候，直接写成静态的html，访问的时候直接从nginx返回。这样做，不仅可以节省服务器资源，还可以利用CDN加速，把文件放到离用户最近的CDN服务器上，既便宜又快。

OSS是另一个可选的方案。OSS的优势是对图片和视频存储做了大师针对性优化，比如缩放图片和视频转码。另外，几乎所有的OSS云服务都自带CDN加速服务。
<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240524102750178.png" alt="image-20240524102750178" style="zoom:67%;" />



FreeMarker 是一款 模板引擎： 即一种基于模板和要改变的数据， 并用来生成输出文本。模板编写为FreeMarker Template Language (FTL)。在模板中，你可以专注于如何展现数据， 而在模板之外可以专注于要展示什么数据。 

MinIO基于Apache License v2.0开源协议的对象存储服务，可以做为云存储的解决方案用来保存海量的图片，视频，文档。由于采用Golang实现，服务端可以工作在Windows,Linux, OS X和FreeBSD上。配置简单，基本是复制可执行程序，单行命令可以运行起来。

MinIO兼容亚马逊S3云存储服务接口，非常适合于存储大容量非结构化的数据，例如图片、视频、日志文件、备份数据和容器/虚拟机镜像等，而一个对象文件可以是任意大小，从几kb到最大5T不等。



### 实现

像一些大文本的内容，一般不会直接去查询数据库，通常做成静态模板进行展示

原始：根据文章ID到数据库中查询文章内容，然后把内容返给页面

现在：根据文章表中的html的url到minIO中去访问当前的静态页面

**实现步骤**

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240513111723538.png" alt="image-20240513111723538" style="zoom:67%;" />



<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240513111649859.png" alt="image-20240513111649859" style="zoom:50%;" />









## 使用Kafka完成异步通知文章上下架的功能

### 同步通讯和异步通讯

微服务间通讯有同步和异步两种方式：

#### 同步通讯feign

同步调用的优点：

- 时效性较强，可以立即得到结果

**同步调用的问题：** 

- 耦合度高：（如下图：产品经理说你支付服务里面在加个短信服务，过一会产品经理又说支付服务里面再加个优惠卷服务，**就造成了每次加入新业务就需要修改支付服务里面原先的代码。存在耦合度高的问题**）
- 性能和吞吐能力下降（就像现在支付服务调用自己的每个服务都是150ms，处理完整的一次请求就是500ms，1秒才能处理两个用户支付请求，**当用户量大，并发量大的时候处理的如此慢。就存在一个性能和吞吐的能力下降的问题**）
- 有额外的资源消耗（**就像支付服务调用订单服务，订单服务处理150ms，其他服务在这150ms内静静的看着，占用着Cpu和内存啥都不干，造成额外的资源浪费**）
- 有[级联](https://so.csdn.net/so/search?q=级联&spm=1001.2101.3001.7020)失败问题 （**假设仓储服务，扛不住压力服务挂了，支付服务调用一直调用都不行，导致支付服务也资源也占用完了服务也挂了，那么这条链路上的服务都不能用了，就造成了级联失败的问题**）



#### 异步通讯

我们以购买商品为例，用户支付后需要调用订单服务完成订单状态修改，调用物流服务，从仓库分配响应的库存并准备发货。

在事件模式中，支付服务是事件发布者（publisher），在支付完成后只需要发布一个支付成功的事件（event），事件中带上订单id。

订单服务和物流服务是事件订阅者（Consumer），订阅支付成功的事件，监听到事件后完成自己业务即可。

为了解除事件发布者与订阅者之间的耦合，两者并不是直接通信，而是有一个中间人（Broker）。发布者发布事件到Broker，不关心谁来订阅事件。订阅者从Broker订阅事件，不关心谁发来的消息。

**好处：**

**1.耦合度极低，每个服务都可以灵活插拔，可替换**（就像项目经理说在支付服务里面再添加一个积分服务，在同步通讯的场景下你还需要在支付服务里面添加代码去调用积分服务。在异步通讯的场景下就不需要了，为什么呢？因为现在支付服务不负责调用自己的子服务，有用户下支付了，支付服务只需要发布一个成功事件到Broker中，Broker拿着喇叭喊一下哪个订单支付了，其关联的服务只需要订阅一下事件，做自己的事就好了，支付服务压根就不管了，或者说产品经理说短信真贵，不让发了只需要取消订阅短信服务就ok了也不需要删除代码，这样就大大的降低了耦合度。）
**2.吞吐量提升：无需等待订阅者处理完成，响应更快速**（这样理解在同步通讯的时候，整个完成的工程需要累加起来也就是500ms，而现在异步通讯就不需要了，当用户发起支付服务，支付动作完成给Borker发布一个事件信息，直接就返回给用户，整个流程下来也就60ms，效率提高，吞吐量也大大提升。而不需要等待订阅者服务处理完成后返回，像（订单服务，仓储服务）它做多久都和支付服务没什么关系，只要最后完成就行。）
**3.故障隔离：服务没有直接调用，不存在级联失败问题**（这个这样理解，你就假如仓储服务挂了出故障了，在同步通讯中极有可能出现级联失败。在异步通讯中就可以避免这种问题，用户支付完成之后，支付服务发布个事件就成功返回了，Borker拿个喇叭一喊这些服务都来订阅，结果仓储服务挂了出现故障了，那没事我修修这个仓储服务，反正支付服务已经成功了也不会造成堵塞，不存在调用关系）

**4.调用间没有阻塞，不会造成无效的资源占用****（在同步通讯操作中一个服务在进行中，其他服务就静静的等着造成资源浪费。在异步通讯中，事件订阅后各干各的不会造成无效的资源占用）**

**5.流量削峰：**不管发布事件的流量波动多大，都由Broker接收，订阅者可以按照自己的速度去处理事件（这个就是，当大量的用户下单了支付服务，然后支付服务就像发洪水一样发布事件到Broker中，但是呢！假设【订单服务，仓储服务，短信服务】一次只能处理一个，如果大批量的订阅搞不好这些服务有挂机了，所以呢！这时候Borker就化身一个大坝把这些支付服务订单事件都给拦下，保证【订单服务，仓储服务，短信服务】能处理几个处理几个保证正常进行，这样就把并发量高峰降低到趋于平稳。）



**缺点：**

**需要依赖于Broker的可靠、安全、性能**(相信大家了解完上面的异步通讯的优势已经明显发现异步通讯需要依赖Broker，当然异步通讯虽然好，但也有缺点，你就像异步通讯处理流量削峰，大量的用户支付生成大量的事件交给了Broker，万一Borker没有抗住压力崩了怎么办呢！就像洪水来了大坝没有建好直接轰然倒塌了，这还能玩吗？所以昂这就是存在的第一个问题就是对Broker的性能，安全，可靠要求很高)

架构复杂了，业务没有明显的流程线，不好管理（**第二个问题就是使用异步通讯服务之间的调用问题不在那么清晰明了**，你发布了一个事件，但是你并不知道这个事件是哪个服务处理的，这种调用链不清晰，就导致以后出了问题，不容易进行排查问题所在。）

好在现在开源软件或云平台上 Broker 的软件是非常成熟的，比较常见的一种就是我们今天要学习的MQ技术。
### 消息队列

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240524110343902.png" alt="image-20240524110343902" style="zoom:80%;" />



#### RabbitMQ和Kafka的比较

**1.语言不同**

RabbitMQ是由内在高并发的erlanng语言开发，用在实时的对可靠性要求比较高的消息传递上。（低延迟

kafka是采用Scala语言开发，它主要用于处理活跃的流式数据,大数据量的数据处理上（高吞吐量

**2.结构不同**

RabbitMQ采用AMQP（Advanced Message Queuing Protocol，高级消息队列协议）是一个进程间传递**异步消息**的**网络协议**

 RabbitMQ的broker由Exchange,Binding,queue组成

kafka采用mq结构：broker 有part 分区的概念

**3.Brokerr与Consume交互方式不同**

RabbitMQ 采用push的方式

kafka采用pull的方式

**4.在集群负载均衡方面**

rabbitMQ的负载均衡需要单独的loadbalancer进行支持。

kafka采用zookeeper对集群中的broker、consumer进行管理

**5.使用场景**

rabbitMQ支持对消息的可靠的传递，支持事务，不支持批量的操作；基于存储的可靠性的要求存储可以采用内存或者硬盘。-----金融场景中经常使用

kafka具有高的吞吐量，内部采用消息的批量处理，zero-copy机制，数据的存储和获取是本地磁盘顺序批量操作，具有O(1)的复杂度（与分区上的存储大小无关），消息处理的效率很高。（大数据）



### 为什么选用Kafka？

Kafka高吞吐量和低延迟

### kafka高可用设计

**集群方案**

- Kafka 的服务器端由被称为 Broker 的服务进程构成，即一个 Kafka 集群由多个 Broker 组成

- 这样如果集群中某一台机器宕机，其他机器上的 Broker 也依然能够对外提供服务。这其实就是 Kafka 提供高可用的手段之一

**备份机制**

如果leader失效后，需要选出新的leader，选举的原则如下：

第一：选举时优先从ISR中选定，因为这个列表中follower的数据是与leader同步的

第二：如果ISR列表中的follower都不行了，就只能从其他follower中选取



### Kafka在分布式下的有序性如何保证？



### 异步通知文章上下架

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240524112957271.png" alt="image-20240524112957271" style="zoom:67%;" />





## 使用redis实现延迟文章的发布，并解决集群下的方法抢占问题

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240524132330143.png" alt="image-20240524132330143" style="zoom:50%;" />







### DelayQueue

![image-20240524124321925](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240524124321925.png)

### RabbitMQ实现延迟队列

通过创建一个延时队列和一个死信队列，将消息发送到延时队列中，在延时时间到达后，消息将被转发到死信队列中。(TTL+DLX)

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240524124519346.png" alt="image-20240524124519346" style="zoom:67%;" />

在RabbitMQ中，延时队列也可以通过x-delayed-message插件实现的，创建一个类型为x-delayed-message的交换机，发送消息时设置x-delay头部，表示延迟时间。消息到期后会被投递到绑定的队列，消费者监听该队列即可。

### Redis实现延迟队列（项目中用

主要利用zset这个数据类型来完成

zset数据类型的去重有序（分数排序）特点进行延迟。例如：时间戳作为score进行排序

![image-20240524130927598](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240524130927598.png)

![image-20240612123941219](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240612123941219.png)



### 讲一下list和zset

Redis 列表**list**是简单的字符串列表，**按照插入顺序排序**，常用命令：

- **LPUSH** key value1 [value2]         将一个或多个值插入到列表头部
- **LRANGE** key start stop                获取列表指定范围内的元素
- **RPOP** key                                       移除并获取列表最后一个元素
- **LLEN** key                                        获取列表长度
- **BRPOP** key1 [key2 ] timeout       移出并获取列表的最后一个元素， 如果列表没有元素会阻塞列表直到等待超    时或发现可弹出元素为止

Redis**有序集合zset**是string类型元素的集合，且**不允许有重复成员**。每个元素都会关联一个double类型的分数，通过这个**分数进行排序**。常用命令：

常用命令：

- **ZADD** key score1 member1 [score2 member2]     向有序集合添加一个或多个成员
- **ZRANGE** key start stop [WITHSCORES]                     通过索引区间返回有序集合中指定区间内的成员
- **ZINCRBY** key increment member                              有序集合中对指定成员的分数加上增量 increment
- **ZREM** key member [member ...]                                移除有序集合中的一个或多个成员

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240612123923516.png" alt="image-20240612123923516" style="zoom:67%;" />

### redis管道(未来数据定时更新)

redis 是 C/S 模式，即客户端 + 服务端。当两端想要通信时，需要先建立特定的 TCP 握手连接，在进行通信时，采用 发送请求 -> 等待响应 这种`一问一答`模式。

这是最经典的一种模式，应用非常广泛。如果你没有批量处理需求，这种模式应该是最合适的。

但如果你遇到一些特殊的场景，比如一次性要查询 100、1000 次 redis，这样的 1000 次的请求 + 应答，主要的消耗都浪费在网络通信中，非常不划算。

那能不能做到一次性批量请求和批量回复？

其实，这种场景不仅是请求 redis，还有很多类似于这种多次请求的诉求，比如 mysql、http 等都会遇到，解决思路就是 批量操作，以减少网络损耗。

Redis 客户端与 Redis 服务器之间使用 TCP 协议进行连接，一个客户端可以通过一个 socket 连接发起多个请求命令。每个请求命令发出后 client 通常会阻塞并等待 redis 服务器处理，redis 处理完请求命令后会将结果通过响应报文返回给 client，因此当执行多条命令的时候都需要等待上一条命令执行完毕才能执行。
而管道（pipeline）可以一次性发送多条命令并在执行完后一次性将结果返回，pipeline 通过减少客户端与 redis 的通信次数来实现降低往返延时时间，而且 Pipeline 实现的原理是队列，而队列的原理是时先进先出，这样就保证数据的顺序性。 Pipeline 的默认的同步的个数为53个，也就是说 arges 中累加到53条数据时会把数据提交。其过程如下图所示：client 可以将三个命令放到一个 tcp 报文一起发送，server 则可以将三条命令的处理结果放到一个 tcp 报文返回。

**定时任务**

@Scheduled(cron = "0 */1 * * * ?")

每分钟执行一次



**实现思路**

获取所有未来数据集合zset的key值

根据执行时间 获取该组key下当前需要消费的任务数据

将这些任务数据添加到消费者队列list中



### 分布式锁解决集群下的方法抢占执行

#### 问题描述

启动两台heima-leadnews-schedule服务，每台服务都会去执行refresh定时任务方法

#### 解决方案（后期可以优化为redisson实现

分布式锁：zookeeper实现；redis实现

我们项目中采用的是redis实现的分布式锁 

sexnx （SET if Not eXists） 命令在指定的 key 不存在时，为 key 设置指定的值。

这种加锁的思路是，如果 key 不存在则为 key 设置 value，如果 key 已存在则 SETNX 命令不做任何操作

#### 实现

在工具类CacheService中添加加锁方法tryLock()



### 为什么不用RabbitMQ实现延迟队列？

**延迟消息支持较弱：** RabbitMQ并不原生支持延迟消息，需要通过插件或者一些变通方法来实现。这使得实现起来可能不如Redis的有序集合直接。

**消息存储方式不同：** RabbitMQ通常会立即将消息存储在队列中，并根据消费者的处理能力进行分发。如果需要延迟发布，需要借助插件或者其他方式来实现延迟投递，这增加了复杂性。

综上所述，使用Redis实现延迟文章发布可以利用其有序集合和定时任务的特性，简单有效地实现延迟发布功能。而选择不使用RabbitMQ主要基于对延迟消息支持的考量，以及实现方式的复杂性和一致性要求。



### 数据库准备阶段涉及到的锁

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240625130223586.png" alt="image-20240625130223586" style="zoom:50%;" />

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240612131950456.png" alt="image-20240612131950456" style="zoom:67%;" />

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240612132047575.png" alt="image-20240612132047575" style="zoom:67%;" />

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240612132117104.png" alt="image-20240612132117104" style="zoom:67%;" />





## 使用elasticsearch，完成app端的文章搜索功能

### ES介绍

ElasticSearch（简称ES）是什么？按照 [ElasticSearch官网](https://www.elastic.co/guide/en/elasticsearch/reference/current/elasticsearch-intro.html) 的定义，Elasticsearch 是一个分布式、RESTful 风格的搜索和数据分析引擎。

数据库是储存和查询数据的利器，那么数据库是否适合做搜索呢？答案是不合适。第一个原因是，当数据库存储了大量数据后，查询效率大幅降低。

另外有些搜索场景，数据库也是不支持的，例如在下表中，我们试图通过“中国A足球”这个关键词搜索数据，数据库是无法查询到相应内容的。

什么是**倒排索引**？倒排索引也叫反向索引，我们通常理解的索引是通过key寻找value，与之相反，倒排索引是通过value寻找key，故而被称作反向索引。

词典和倒排表是 [Lucene](https://so.csdn.net/so/search?q=Lucene&spm=1001.2101.3001.7020)这种很重要的两种数据结构，是实现快速检索的重要基石。词典和倒排文件是分两部分存储的，词典在内存中而倒排文件存储在磁盘。

ElasticSearch就在Lucene的基础上实现的，对Lucene进行了良好的封装，简化开发，并提供了很多高级功能。ES就是分布式的集群，每一个节点其实就是Lucene，当用户搜索的时候，会随机挑一台，然后这台机器自己知道数据在哪，不用我们管这些底层

### ES特点

反向索引又叫倒排索引，是根据文章内容中的关键字建立索引。
搜索引擎原理就是建立反向索引。
Elasticsearch 在 Lucene 的基础上进行封装，实现了分布式搜索引擎。
Elasticsearch 中的索引、类型和文档的概念比较重要，类似于 MySQL 中的数据库、表和行。
Elasticsearch 也是 Master-slave 架构，也实现了数据的分片和备份。
Elasticsearch 一个典型应用就是 ELK 日志分析系统。

### 用数据库实现搜索功能的弊端

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240525110442616.png" alt="image-20240525110442616" style="zoom:67%;" />

### ES和mysql的对比

**1.结构对比**

![image-20240525110859787](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240525110859787.png)

**2.适用场景不同**

mysql：更擅长的是事务的操作，事务里面有原子性、持久性、一致性、隔离性这些，因此可以保证数据的安全性、持久化存储、数据一致. 
es：es 中就没有事务的概念了，他更擅长的数据的搜索分析和运算.
例如，现在要做一个下单付款这样的业务，对事务的要求很高，因此就应该使用 mysql 去存储；如果你先在做到是一个商品搜索，或者是页面搜索，这种搜索比较复杂（比如用户通过关键词搜索所有相关信息），那么就需要使用 es 去做.
他们在系统架构中是一种互补的关系，比如我们的用户做一个商品订单的搜索，因为 es 的搜索能力更强，所以这里使用 es 进行搜索，那么也意味着，es 这边也要有数据，那怎么确保两边都有数据呢？一般写数据，是写在 mysql 中的（为了数据的安全性以及持久化等特性，mysql 用来存储全量数据），并且 mysql 也会将数据同步给 es，从而实现数据的双写，将来也就是一个互补的效果了.



### ES和mysql的数据一致性

**回答：** 为了保证数据一致性，可以采用以下策略：

- 实时同步：使用消息队列（如Kafka、RabbitMQ）或者通过数据库的触发器将数据变更事件发送给Elasticsearch进行实时索引更新。
- 定时同步：定期从数据库中拉取更新的数据，利用Elasticsearch的Bulk API批量更新索引。
- 版本控制：使用版本控制和乐观锁机制来处理并发更新，确保不会出现数据丢失或冲突。

![image-20240624141628196](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240624141628196.png)

### 



### 1.app端文章搜索

![image-20240525115737190](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240525115737190.png)



### 2.添加文章时在ES中添加数据（kafka)

![image-20240509100022012](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240509100022012.png)

发送消息的逻辑写在ArticleFreemarkServiceImpl中将文章上传到minIO之后



### 优化--将数据库中的数据批量导入到ES库

countDownLatch+线程池（参考黑马八股视频

![image-20240612125624224](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240612125624224.png)



### ES库中面对大的热数据如何处理？

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240612133616100.png" alt="image-20240612133616100" style="zoom:67%;" />



## 使用MongoDB完成用户搜索记录的保存、加载、删除和关键字联想等功能

MongoDB是一个基于文档的分布式NoSQL数据库，使用JSON-like的BSON（Binary JSON）格式存储数据。与传统关系型数据库相比，MongoDB具有更灵活的数据模型、水平扩展能力强、适应非结构化和半结构化数据存储的特点。选择MongoDB来存储用户搜索记录，主要是因为搜索记录可以视为文档形式的非结构化数据，适合用MongoDB的文档存储模型来存储和查询

## 关系型数据库vs非关系型数据库

![image-20240615131509483](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240615131509483.png)

### MongoDB

一个`MongoDB `实例可以包含一组数据库，一个`DataBase `可以包含一组`Collection`（集合），一个集合可以包含一组`Document`（文档）。    **集合就是一组文档，类似于关系数据库中的表。**

**文档中的值不仅可以是双引号中的字符串，也可以是其他的数据类型，例如，整型、布尔型等，也可以是另外一个文档，即文档可以嵌套。文档中的键类型只能是字符串**。

一个`Document`包含一组`field`（字段），每一个字段都是一个`key/value pair`

- `key`: 必须为字符串类型

- ```
  value
  ```

  ：可以包含如下类型

  - 基本类型，例如，`string，int，float，timestamp，binary` 等类型
  - 一个`document`
  - 数组类型

### Redis  VS  MongoDB

Redis的数据存储主要依赖于内存，因此其存储容量受到物理内存的限制。虽然支持持久化机制，但主要是为了保障数据的持久性，存储量一般较小。
Redis适合需要快速读写、对数据结构操作较多的场景，如缓存、实时计数等。

MongoDB的数据存储基于磁盘，可以存储比内存更大容量的数据。它更适合存储大规模数据集，数据可以超出物理内存容量。
MongoDB适合需要复杂查询和大规模数据存储的场景，如Web应用、分析、内容管理等。

### MongoDB适用场景

MongoDB适合以下几种应用场景：

社交场景：使用MongoDB存储用户信息，朋友圈信息，通过地理位置索引实现附近的人、定位功能。
物联网场景：使用MongoDB存储设备信息、设备汇报的日志信息、并对这些信息进行多维度分析。
视频直播：使用MongoDB存储用户信息、点赞互动信息。
内容管理：使用MongoDB存储文章、评论、标签等内容，支持全文搜索、分类、排序等功能。

### MongDb与关系型数据库相比

优点：

③文档结构的存储方式，能够更便捷的获取数据。

对于一个层级式的数据结构来说，如果要将这样的数据使用扁平式的，表状的结构来保存数据，这无论是在查询还是获取数据时都十分困难。

③内置GridFS，支持大容量的存储。

  GridFS是一个出色的分布式文件系统，可以支持海量的数据存储。
  内置了GridFS了MongoDB，能够满足对大数据集的快速范围查询。

⑤第三方支持丰富。(这是与其他的NoSQL相比，MongoDB也具有的优势)

⑥性能优越：

在使用场合下，千万级别的文档对象，近10G的数据，对有索引的ID的查询不会比mysql慢，而对非索引字段的查询，则是全面胜出。 mysql实际无法胜任大数据量下任意字段的查询，而mongodb的查询性能实在让我惊讶。写入性能同样很令人满意，同样写入百万级别的数 据，mongodb比我以前试用过的couchdb要快得多，基本10分钟以下可以解决。补上一句，观察过程中mongodb都远算不上是CPU杀手。

缺点：

***\*①mongodb不支持事务操作。\****

***\*②mongodb占用磁盘空间过大。\****

***\*②mongodb占用空间过大。\****



### Mongodb与redis相比

Redis和MongoDB之间的一些比较：

1.数据模型：
Redis：Redis是一个键值存储系统，支持多种数据结构如字符串、哈希、列表、集合和有序集合。数据以键值对的形式存储，可以通过键快速访问数据。Redis适合用于缓存、会话存储和快速查询等场景。
MongoDB：MongoDB是一个面向文档的数据库，数据以类似JSON的BSON文档格式存储。每个文档都有一个唯一的ID，并且文档可以嵌套。MongoDB适合存储和查询复杂的数据结构和大规模数据集。
2.数据持久化：
Redis：Redis支持持久化，可以将数据保存到磁盘上，以防止数据丢失。它提供了快照（snapshotting）和AOF（Append-only file）两种持久化方式。
MongoDB：MongoDB也支持持久化，将数据写入磁盘文件中。它使用写时复制（write-ahead logging）机制来保证数据的一致性和持久性。
3.查询功能：
Redis：Redis提供了一些查询功能，如对字符串的模糊匹配、对集合的交并差等操作。然而，它并不是一个完整的查询语言，不支持复杂查询和索引，适合用于简单的数据检索。
MongoDB：MongoDB提供了强大的查询功能，支持丰富的查询语法和索引，可以进行复杂的查询操作，包括范围查询、正则表达式、聚合管道等。
4.扩展性：
Redis：Redis采用单线程模型，通过异步I/O来实现高性能。它可以通过主从复制和分片来扩展读性能和存储容量。
MongoDB：MongoDB采用分布式架构，支持水平扩展和分片。它可以在集群中添加更多的节点来扩展存储和处理能力。
5.事务支持：
Redis：Redis支持事务，可以将多个操作组合成一个原子性的操作序列。但是，Redis的事务是非严格的，即事务中的某个操作失败不会回滚其他操作。
MongoDB：MongoDB支持多文档事务，可以对多个文档进行原子性操作，保证事务的一致性。
6.数据一致性：
Redis：Redis默认情况下是单机数据库，数据复制和故障恢复依赖于主从复制和Sentinel哨兵机制。在主节点故障时，可能会出现一段时间的数据不一致。
MongoDB：MongoDB支持复制集和分片集群，在故障时可以实现数据的自动备份和故障转移，提供更高的数据一致性和可用性。

**总体来说，Redis适用于高性能的键值存储和缓存场景，而MongoDB适用于更复杂的数据存储和查询需求，特别是对复杂数据结构和丰富查询功能的支持。具体选择应根据实际应用需求和数据模型的特点进行评估**

### Mongodb与ES相比

[Elasticsearch](https://so.csdn.net/so/search?q=Elasticsearch&spm=1001.2101.3001.7020)（ES）和MongoDB是两个非常知名的NoSQL数据库，但它们的定位和使用场景并不完全相同。[NoSQL数据库](https://so.csdn.net/so/search?q=NoSQL数据库&spm=1001.2101.3001.7020)主要分为四类：键值存储、文档存储、列存储和图形数据库。ES和MongoDB都是文档存储型数据库，但它们的设计目标和应用场景有所不同。

![image-20240525135821428](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240525135821428.png)

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240525135858449.png" alt="image-20240525135858449" style="zoom:80%;" />

![image-20240528191440667](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240528191440667.png)



### 1.保存搜索记录

用户的搜索记录，需要给每一个用户都保存一份，数据量较大，要求加载速度快，通常这样的数据存储到mongodb更合适，不建议直接存储到关系型数据库中

![image-20240509101609770](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240509101609770.png)

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240509103108505.png" alt="image-20240509103108505" style="zoom:50%;" />



<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240509103136046.png" alt="image-20240509103136046" style="zoom:50%;" />

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240509103207051.png" alt="image-20240509103207051" style="zoom:50%;" />



这个功能是在文章搜索功能的实现类中，在第一步检查参数结束之后，异步调用 保存搜索记录（**p14（这里涉及到网关中过滤器获取用户信息并存入header中  和拦截器中解析header将apUser.userId放入ThreadLocal中**

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240509102933491.png" alt="image-20240509102933491" style="zoom:50%;" />

### 2.加载搜索记录列表

### 3.删除搜索记录

### 4.关键字联想词

根据用户输入的关键字展示联想词

用mongdb实现  在查询前已经将联想词表ap_associate_words.js导入到mongo中



### 5. 优化 -- 保存搜索记录

异步调用＋线程池

![image-20240612130823591](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240612130823591.png)



## 使用xxl-job分布式任务调度框架实现热点文章的的定时计算

### 实现定时任务方式

1.使用SpringTask实现单体服务的任务调度

1. 添加Maven坐标。
2. 启动类添加@EnableScheduling开启任务调度。
3. 方法上添加@Scheduled注解，并设置**cron表达式。**

**关于单机定时任务的实现，如果是分布式环境可以使用 Redis 来实现定时任务。**



2.使用xxl-job分布式任务调度框架

登录调度中心创建执行器和任务

在pom文件中加入XXL-job依赖

创建配置类并交给Spring容器的Bean进行管理

创建任务代码并通过@[XxlJob](https://so.csdn.net/so/search?q=XxlJob&spm=1001.2101.3001.7020)注解指定JobHandler







### 使用SpringTask的不足

spring传统的定时任务@Scheduled，但是这样存在这一些问题 ：

- 做集群任务的重复执行问题（分布式锁解决

- cron表达式定义在代码之中，修改不方便

- 定时任务失败了，无法重试也没有统计

- 如果任务量过大，不能有效的分片执行

用分布式锁或者zookeeper耦合度较高，因此我们选用xxl-job分布式调度架构

### 分布式和微服务的区别

![image-20240527142041188](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240527142041188.png)



由于分布式将某个业务服务创建多个相同的服务，故在每一个服务中均存在相同的任务调度程序，此时在相同时刻多个服务中的任务调度程序均会执行，从而造成业务故障。如：电商系统定期发放优惠券，就可能重复发放优惠券，对公司造成损失，信用卡还款提醒就会重复执行多次，给用户造成烦恼，所以我们需要控制相同的任务在多个运行实例上只执行一次。


### xxl-job分布式任务调度框架

#### 设计思想

1、将调度行为抽象形成“调度中心”公共平台，而平台自身并不承担业务逻辑，“调度中心”负责发起调度请求。

2、将任务抽象成分散的JobHandler，交由“执行器”统一管理，“执行器”负责接收调度请求并执行对应的JobHandler中业务逻辑。因此，“调度”和“任务”两部分可以相互解耦，提高系统整体稳定性和扩展性；

分布式：在微服务架构下一个微服务实例具有多个实现，即集群模式。【分布式和微服务并不是一个概念，微服务强调的是将单个服务根据不同的业务逻辑进行拆分，而分布式强调的是针对具体的拆分的某个实例创建多个同样的服务以集群的方式存在。】
分布式任务调度：本质仍然是上面提到的任务调度，唯一不同的是此时针对的是一个服务实例的多个实现进行的调度。

#### 优势

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240527142940669.png" alt="image-20240527142940669" style="zoom:80%;" />

### 定时计算具体实现

![image-20240527114514097](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240527114514097.png)



1.在article微服务下的HotarticleImpl下，先检索出前五天所有的文章数据，并计算出其分值

2.feign远程调用wemedia微服务检索出有几个频道

3.按频道检索出每个频道的文章

4.给文章进行排序，取30条分值较高的文章存入redis （ key：频道id   value：30条分值较高的文章）

即cacheService.set(key, JSON.toJSONString(hotArticleVos));

5.测试前要启动wemedia , schedule微服务

**定时任务**

1.在xxl-job-admin中新建执行器和任务

新建执行器：leadnews-hot-article-executor

新建任务：路由策略为轮询，Cron表达式：0 0 2 * * ? （每天凌晨2点执行一次）



2.leadnews-article中集成xxl-job（参考xxljob-demo项目

即article微服务下的config创建XxlJobConfig类添加相关配置（参考xxljob-demo项目），其中一些属性的赋值放到nacos中

3.leadnews-article微服务下的job目录下创建具体任务ComputeHotArticleJob

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240510210142496.png" alt="image-20240510210142496" style="zoom:67%;" />





# 苍穹外卖

## 通过Spring Boot框架搭建后端系统，获取并处理通过Nginx反向代理后的前端发出的HTTP请求，通过MyBatis实现对数据库的操作完成信息的处理

spring boot自动配置原理

nginx的配置



mybatis执行流程  延迟加载  一二级缓存  #{}和${}



## 使用JWT令牌技术，用自定义拦截器完成用户认证，并通过ThreadLocal存储各自线程的用户信息

JWT令牌技术

拦截器 和 过滤器

### ThreadLocal

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240618122845936.png" alt="image-20240618122845936" style="zoom:67%;" />

用户登录流程



## 使用Spring Task实现了订单状态的定时处理，超时自动取消订单等功能（day10

  Spring Task（Spring 任务调度）是 Spring 框架提供的一种任务调度框架，用于执行定时任务、异步任务、任务监听、任务调度等。

>    在苍穹外卖项目中使用 Spring task 
>
>    用户下单后可能存在的情况：
>
>    - 下单后未支付，订单一直处于**“待支付”**状态
>    - 用户收货后管理端未点击完成按钮，订单一直处于**“派送中”**状态
>
>    1. 通过定时任务每分钟检查一次是否存在支付超时订单（下单后超过15分钟仍未支付则判定为支付超时订单），如果存在则修改订单状态为“已取消”
>    2. 通过定时任务每天凌晨1点检查一次是否存在“派送中”的订单，如果存在则修改订单状态为“已完成”



**使用步骤**

1). 导入maven坐标 spring-context（已存在）

2). 启动类添加注解 @EnableScheduling 开启任务调度

3). 自定义定时任务类  @Scheduled注明执行频率

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240620122541486.png" alt="image-20240620122541486" style="zoom:50%;" />

## 通过WebSocket实现客户端和服务端的长连接，实现来单提醒和客户催单等功能(day10)

后端如何与商家端建立链接，实现实时通信？(day10 来单提醒 客户催单

使用 Websocket 来实现用户端和商家端通信：
**WebSocket** 是一种在 Web 应用程序中实现双向通信的协议。它允许客户端和服务器之间建立持久的、双向的通信通道，使得服务器可以主动向客户端推送消息，而无需客户端发送请求。
**客户端和服务器之间可以实时地发送消息和接收消息**，不需要频繁地发起请求。这样可以减少网络流量和延迟，并提供更好的用户体验。

> - 通过WebSocket实现管理端页面和服务端保持长连接状态

>用户下单并且支付成功后，需要第一时间通知外卖商家。
>来单提醒
- 当客户支付后，调用WebSocket的相关API实现服务端向客户端推送消息
- 客户端浏览器解析服务端推送的消息，判断是来单提醒还是客户催单，进行相应的消息提示和语音播报
- 约定服务端发送给客户端浏览器的数据格式为JSON，字段包括：type，orderId，content
  - type 为消息类型，1为来单提醒 2为客户催单
  - orderId 为订单id
  - content 为消息内容

>用户在小程序中点击催单按钮后，需要第一时间通知外卖商家。
>*客户催单
- 通过WebSocket实现管理端页面和服务端保持长连接状态
- 当用户点击催单按钮后，调用WebSocket的相关API实现服务端向客户端推送消息
- 客户端浏览器解析服务端推送的消息，判断是来单提醒还是客户催单，进行相应的消息提示和语音播报
  约定服务端发送给客户端浏览器的数据格式为JSON，字段包括：type，orderId，content
  - type 为消息类型，1为来单提醒 2为客户催单
  - orderId 为订单id
  - content 为消息内容

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240618122513575.png" alt="image-20240618122513575" style="zoom:67%;" />

### Websocket 与 HTTP 有什么区别？ 既然 WebSocket 支持双向通信，功能看似比 HTTP 强大，那么是不是可以基于 WebSocket 开发所有的业务功能？

  **HTTP 协议和 WebSocket 协议对比：**

  - HTTP 是**短连接**
  - WebSocket 是**长连接**
  - HTTP 通信是**单向**的，基于请求响应模式
  - WebSocket 支持**双向**通信
  - HTTP 和 WebSocket 底层都是 TCP 连接

不能使用 WebSocket 并不能完全取代 HTTP，它只适合在特定的场景下使用，原因如下：

  1. **资源开销**：WebSocket 需要保持持久连接，对服务器资源有更高要求，不适合所有场景。
  2. **功能与约定**：HTTP 提供丰富的功能和约定（如状态码、缓存控制），适合更广泛的业务需求。
  3. **安全性和兼容性**：虽然 WebSocket 支持加密，但管理安全性可能更复杂；且某些环境下 WebSocket 不被支持或有限制。
  4. **设计和实践**：RESTful API 和相关的 HTTP 设计原则不易直接应用于 WebSocket。





## 使用Redis对菜品进行缓存，缓解了高并发环境下频繁访问数据库造成的性能下降问题

Spring 对 Redis 客户端进行了整合，提供了 Spring Data Redis，在Spring Boot项目中还提供了对应的Starter，即 spring-boot-starter-data-redis。

Spring Data Redis 是 Spring 的一部分，提供了在 Spring 应用中通过简单的配置就可以访问 Redis 服务，对 Redis 底层开发包进行了高度封装。在 Spring 项目中，可以使用Spring Data Redis来简化 Redis 操作。

Spring Data Redis中提供了一个高度封装的类：**RedisTemplate**



  - SpringCache 是 Spring 框架提供的一个抽象层，旨在提供一种透明的方式来缓存应用中的数据。SpringCache 不是一个具体的缓存实现，而是一个集成不同缓存解决方案的接口，如 EHCache、Caffeine、Guava、Redis 等。它允许开发者通过简单的注解来控制方法的缓存行为，例如，使用 `@Cacheable` 来标记一个方法的返回值应该被缓存，以及使用 `@CacheEvict` 来标记何时移除缓存。SpringCache 为应用提供了一致的缓存视图，而开发者不需要关心具体使用哪种缓存技术。

  - 简单的说：它也是一种缓存技术，使得所用工具不局限于 Redis。相比较于使用 Redis 的时候需要把相关代码内嵌到方法体种，Spring Cache 是一种基于注解方式来达到内嵌代码相同的效果。

**项目中的应用**

**存在问题：** 用户端小程序展示的菜品数据都是通过查询数据库获得，如果用户端访问量比较大，数据库访问压力随之增大。
**结果：** 系统响应慢、用户体验差
通过Redis来缓存菜品数据，减少数据库查询操作。
**缓存逻辑分析：**

- 每个分类下的菜品保存一份缓存数据
- 数据库中菜品数据有变更时清理缓存数据
- Spring Cache 是一个框架，实现了基于注解的缓存功能，只需要简单地加一个注解，就能实现缓存功能。
Spring Cache 提供了一层抽象，底层可以切换不同的缓存实现，例如： EHCache、 Caffeine、Redis(常用)

为了保证**数据库**和**Redis**中的数据保持一致，修改**管理端接口 DishController** 的相关方法，加入清理缓存逻辑。
> 缓存套餐
> 1). 导入Spring Cache和Redis相关maven坐标
> 2). 在启动类上加入@EnableCaching注解，开启缓存注解功能
> 3). 在用户端接口SetmealController的 list 方法上加入@Cacheable注解
> 4). 在管理端接口SetmealController的 save、delete、update、startOrStop等方法上加入CacheEvict注解





## 怎么保证在同时操作多张数据库表出现程序错误时保证数据的一致性？(事务  AOP  代理技术)

### 事务

**我在涉及多表操作时使用了事务（Transaction）：** 将涉及到的数据库操作封装在一个事务中。在事务中，要么所有的数据库操作都成功提交，要么全部失败回滚，保证了数据的一致性。如果发生异常，可以通过捕获异常并执行回滚操作来保证数据的一致性。
 **具体操作：**

- 在启动类上方添加@EnableTransactionManagement

- 开启事务注解之后，我们只需要在需要捆绑成为一个事务的方法上添加@Transactional

- 这样就把对两张表的操作捆绑成为了一个事务。

- 

  **项目具体用处** 
  在用户下单功能的serviceImpl中
  出现的问题是在order表中插入数据成功而因为在orderDetail的mapper.xml中sql语句编写的错误导致orderDetail表中插入数据失败，因此此时需要事务回滚



### AOP

- 概念：

  AOP（Aspect-Oriented Programming，面向切面编程）是一种编程范式，旨在通过将横切关注点（cross-cutting concerns）从核心业务逻辑中分离出来，以提高代码的模块化性、可维护性和复用性。

  - 横切关注点：
    比如日志、事务、安全性等，这些关注点会横跨多个模块，导致代码重复、耦合性增加、难以维护等问题。AOP 通过将这些横切关注点抽象成一个个“切面”（Aspect），并将其独立于业务逻辑之外，以达到解耦的目的。

- AOP 的核心概念包括以下几个要素：

  1. **切面（Aspect）：** 切面是横切关注点的抽象，它包含了一组横切关注点以及在何时何处应用这些关注点的逻辑。通常，切面由一组通知（Advice）和一个切点（Pointcut）组成。
  2. **通知（Advice）：** 通知是切面中具体的逻辑实现，它定义了在何时何地执行横切关注点的具体行为，包括“前置通知”（Before Advice）、“后置通知”（After Advice）、“环绕通知”（Around Advice）等。
  3. **切点（Pointcut）：** 切点是在程序中指定的某个位置，通知将在这些位置执行。切点可以使用表达式或其他方式进行定义，以便匹配到程序中的特定方法或代码块。
  4. **连接点（Join Point）：** 连接点是在程序执行过程中可以应用通知的具体位置，通常是方法调用、方法执行或异常抛出等。
  5. **织入（Weaving）：** 织入是将切面逻辑应用到目标对象中的过程，可以在编译时、加载时或运行时进行。织入可以通过源代码修改、字节码操作、动态代理等方式实现。

![在这里插入图片描述](https://img-blog.csdnimg.cn/direct/bdc70d9307844d8a89b7592687d01b80.png)

### 代理技术

代理模式：
二十三种设计模式中的一种，属于结构型模式。它的作用就是通过提供一个代理类，让我们在调用目标方法的时候，不再是直接对目标方法进行调用，而是通过代理类间接调用。让不属于目标方法核心逻辑的代码从目标方法中剥离出来——解耦。调用目标方法时先调用代理对象的方法，减少对目标方法的调用和打扰，同时让附加功能能够集中在一起也有利于统一维护。
== 静态代理==
**静态代理**，主动创建代理类，将被代理的目标对象声明为成员变量，附加功能由代理类中的代理方法来实现，通过目标对象来实现核心业务逻辑。
**静态代理**确实实现了解耦，但是由于代码都写死了，完全不具备任何的灵活性。就拿日志功能来说，将来其他地方也需要附加日志，那还得再声明更多个静态代理类，那就产生了大量重复的代码，日志功能还是分散的，没有统一管理。
提出进一步的需求：将日志功能集中到一个代理类中，将来有任何日志需求，都通过这一个代理类来实现。这就需要使用动态代理技术了。
== 动态代理==
动态代理技术分类

- **JDK动态代理**：JDK原生的实现方式，需要被代理的目标类必须**实现接口**！他会根据目标类的接口动态生成一个代理对象！代理对象和目标对象有相同的接口！（拜把子）
- **cglib**：通过继承被代理的目标类实现代理，所以不需要目标类实现接口！（认干爹）
- 
- 代理总结
  **代理方式可以解决附加功能代码干扰核心代码和不方便统一维护的问题！**
  他主要是将附加功能代码提取到代理中执行，不干扰目标核心代码！
  但是我们也发现，无论使用静态代理和动态代理(jdk,cglib)，程序员的工作都比较繁琐！
  需要自己编写代理工厂等！
  但是，提前剧透，我们在实际开发中，不需要编写代理代码，我们可以使用**Spring AOP框架**，
  他会简化动态代理的实现！！！
  Spring AOP框架，基于AOP编程思维，封装动态代理技术，简化动态代理技术实现的框架！SpringAOP内部帮助我们实现动态代理，我们只需写少量的配置，指定生效范围即可,即可完成面向切面思维编程的实现！



## 新增员工代码完善1和2（day02

- 录入的用户名已存，抛出的异常后没有处理
- 新增员工时，创建人id和修改人id设置为固定值

完善一：涉及到全局异常处理器

完善2：涉及到jwt  ThreadLocal



## 文件上传功能

苍穹外卖用的是 阿里云的OSS文件存储服务

黑马头条用的是 分布式文件存储系统MinIo





# 简历技能

## 多线程：熟悉线程状态转换、CAS、AQS、死锁问题、线程安全、线程池等。

## 熟悉JVM内存结构、垃圾回收的过程、双亲委派机制、类加载过程

## 熟悉关系型数据库MySQL，熟悉MySQL的事务、索引原理和索引优化、事务隔离级别、MVCC机制，了解MySQL的体系结构和SQL语句的内部执行流程

## 熟悉非关系型数据库Redis，熟悉缓存持久化、缓存更新策略、分布式锁、集群模式、布隆过滤器等，了解熟悉缓存穿透、缓存雪崩、缓存击穿。





Ÿ JavaSE基础：熟悉基本数据类型、面向对象三大特性、常用集合框架。

Ÿ 掌握常用的数据结构(链表、栈、队列、二叉树等)，熟练使用排序、贪心、动态规划等算法。

Ÿ 多线程：熟悉线程状态转换、CAS、AQS、死锁问题、线程安全、线程池等。

Ÿ 熟悉Spring、Spring MVC、MyBatis、Spring MVC、Spring Cloud等主流框架的使用，熟悉IOC和AOP，了解事务传播机制、对象生命周期、Spring MVC处理流程、Spring Boot自动装配原理。

Ÿ 熟悉RabbitMQ、Kafka等消息队列的使用，掌握高可用机制，消息可靠性，重复消费等问题解决方式。
